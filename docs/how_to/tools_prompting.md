---
custom_edit_url: https://github.com/langchain-ai/langchain/edit/master/docs/docs/how_to/tools_prompting.ipynb
sidebar_position: 3
---

# å¦‚ä½•ä¸º LLM å’ŒèŠå¤©æ¨¡å‹æ·»åŠ ä¸´æ—¶å·¥å…·è°ƒç”¨èƒ½åŠ›

:::caution

æŸäº›æ¨¡å‹å·²ç»é’ˆå¯¹å·¥å…·è°ƒç”¨è¿›è¡Œäº†å¾®è°ƒï¼Œå¹¶æä¾›äº†ä¸“ç”¨çš„ API è¿›è¡Œå·¥å…·è°ƒç”¨ã€‚é€šå¸¸ï¼Œè¿™äº›æ¨¡å‹åœ¨å·¥å…·è°ƒç”¨æ–¹é¢ä¼˜äºæœªå¾®è°ƒçš„æ¨¡å‹ï¼Œæ¨èç”¨äºéœ€è¦å·¥å…·è°ƒç”¨çš„ç”¨ä¾‹ã€‚æœ‰å…³æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚è§ [å¦‚ä½•ä½¿ç”¨èŠå¤©æ¨¡å‹è°ƒç”¨å·¥å…·](/docs/how_to/tool_calling) æŒ‡å—ã€‚

:::

:::info å‰ææ¡ä»¶

æœ¬æŒ‡å—å‡è®¾æ‚¨ç†Ÿæ‚‰ä»¥ä¸‹æ¦‚å¿µï¼š

- [LangChain å·¥å…·](/docs/concepts/#tools)
- [å‡½æ•°/å·¥å…·è°ƒç”¨](https://python.langchain.com/v0.2/docs/concepts/#functiontool-calling)
- [èŠå¤©æ¨¡å‹](/docs/concepts/#chat-models)
- [LLMs](/docs/concepts/#llms)

:::

åœ¨æœ¬æŒ‡å—ä¸­ï¼Œæˆ‘ä»¬å°†çœ‹åˆ°å¦‚ä½•ä¸ºèŠå¤©æ¨¡å‹æ·»åŠ  **ä¸´æ—¶** å·¥å…·è°ƒç”¨æ”¯æŒã€‚è¿™æ˜¯ä¸€ç§æ›¿ä»£æ–¹æ³•ï¼Œç”¨äºè°ƒç”¨ä¸åŸç”Ÿæ”¯æŒ [å·¥å…·è°ƒç”¨](/docs/how_to/tool_calling) çš„æ¨¡å‹ã€‚

æˆ‘ä»¬å°†é€šè¿‡ç®€å•åœ°ç¼–å†™ä¸€ä¸ªæç¤ºæ¥å®ç°è¿™ä¸€ç‚¹ï¼Œä»¥ä½¿æ¨¡å‹è°ƒç”¨é€‚å½“çš„å·¥å…·ã€‚ä»¥ä¸‹æ˜¯é€»è¾‘çš„å›¾ç¤ºï¼š

![chain](../../static/img/tool_chain.svg)

## è®¾ç½®

æˆ‘ä»¬éœ€è¦å®‰è£…ä»¥ä¸‹è½¯ä»¶åŒ…ï¼š

```python
%pip install --upgrade --quiet langchain langchain-community
```

å¦‚æœæ‚¨æƒ³ä½¿ç”¨ LangSmithï¼Œè¯·å–æ¶ˆä¸‹é¢çš„æ³¨é‡Šï¼š

```python
import getpass
import os
# os.environ["LANGCHAIN_TRACING_V2"] = "true"
# os.environ["LANGCHAIN_API_KEY"] = getpass.getpass()
```

æ‚¨å¯ä»¥é€‰æ‹©æœ¬æŒ‡å—ä¸­æä¾›çš„ä»»ä½•æ¨¡å‹ã€‚è¯·è®°ä½ï¼Œè¿™äº›æ¨¡å‹å¤§å¤šæ•°å·²ç» [æ”¯æŒåŸç”Ÿå·¥å…·è°ƒç”¨](/docs/integrations/chat/)ï¼Œå› æ­¤åœ¨è¿™é‡Œä½¿ç”¨çš„æç¤ºç­–ç•¥å¯¹è¿™äº›æ¨¡å‹æ²¡æœ‰æ„ä¹‰ï¼Œæ‚¨åº”è¯¥éµå¾ª [å¦‚ä½•ä½¿ç”¨èŠå¤©æ¨¡å‹è°ƒç”¨å·¥å…·](/docs/how_to/tool_calling) æŒ‡å—ã€‚

import ChatModelTabs from "@theme/ChatModelTabs";

<ChatModelTabs openaiParams={`model="gpt-4"`} />

ä¸ºäº†è¯´æ˜è¿™ä¸ªæƒ³æ³•ï¼Œæˆ‘ä»¬å°†é€šè¿‡ Ollama ä½¿ç”¨ `phi3`ï¼Œå®ƒ **ä¸** æ”¯æŒåŸç”Ÿå·¥å…·è°ƒç”¨ã€‚å¦‚æœæ‚¨ä¹Ÿæƒ³ä½¿ç”¨ `Ollama`ï¼Œè¯·éµå¾ª [è¿™äº›è¯´æ˜](/docs/integrations/chat/ollama/)ã€‚

```python
from langchain_community.llms import Ollama

model = Ollama(model="phi3")
```

## åˆ›å»ºå·¥å…·

é¦–å…ˆï¼Œè®©æˆ‘ä»¬åˆ›å»ºä¸€ä¸ª `add` å’Œ `multiply` å·¥å…·ã€‚æœ‰å…³åˆ›å»ºè‡ªå®šä¹‰å·¥å…·çš„æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚é˜… [æ­¤æŒ‡å—](/docs/how_to/custom_tools)ã€‚

```python
from langchain_core.tools import tool


@tool
def multiply(x: float, y: float) -> float:
    """Multiply two numbers together."""
    return x * y


@tool
def add(x: int, y: int) -> int:
    "Add two numbers."
    return x + y


tools = [multiply, add]

# Let's inspect the tools
for t in tools:
    print("--")
    print(t.name)
    print(t.description)
    print(t.args)
```
```output
--
multiply
Multiply two numbers together.
{'x': {'title': 'X', 'type': 'number'}, 'y': {'title': 'Y', 'type': 'number'}}
--
add
Add two numbers.
{'x': {'title': 'X', 'type': 'integer'}, 'y': {'title': 'Y', 'type': 'integer'}}
```

```python
multiply.invoke({"x": 4, "y": 5})
```



```output
20.0
```

## åˆ›å»ºæˆ‘ä»¬çš„æç¤º

æˆ‘ä»¬å¸Œæœ›ç¼–å†™ä¸€ä¸ªæç¤ºï¼ŒæŒ‡å®šæ¨¡å‹å¯ä»¥è®¿é—®çš„å·¥å…·ã€è¿™äº›å·¥å…·çš„å‚æ•°ï¼Œä»¥åŠæ¨¡å‹æ‰€éœ€çš„è¾“å‡ºæ ¼å¼ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬å°†æŒ‡ç¤ºå®ƒè¾“å‡ºä¸€ç§å½¢å¼ä¸º `{"name": "...", "arguments": {...}}` çš„ JSON æ•°æ®å—ã€‚


```python
from langchain_core.output_parsers import JsonOutputParser
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.tools import render_text_description

rendered_tools = render_text_description(tools)
print(rendered_tools)
```
```output
multiply(x: float, y: float) -> float - å°†ä¸¤ä¸ªæ•°å­—ç›¸ä¹˜ã€‚
add(x: int, y: int) -> int - å°†ä¸¤ä¸ªæ•°å­—ç›¸åŠ ã€‚
```

```python
system_prompt = f"""\
æ‚¨æ˜¯ä¸€ä¸ªåŠ©æ‰‹ï¼Œå¯ä»¥è®¿é—®ä»¥ä¸‹å·¥å…·é›†ã€‚ 
ä»¥ä¸‹æ˜¯æ¯ä¸ªå·¥å…·çš„åç§°å’Œæè¿°ï¼š

{rendered_tools}

æ ¹æ®ç”¨æˆ·è¾“å…¥ï¼Œè¿”å›è¦ä½¿ç”¨çš„å·¥å…·çš„åç§°å’Œè¾“å…¥ã€‚ 
å°†æ‚¨çš„å“åº”ä½œä¸ºä¸€ä¸ªå¸¦æœ‰ 'name' å’Œ 'arguments' é”®çš„ JSON æ•°æ®å—è¿”å›ã€‚

`arguments` åº”è¯¥æ˜¯ä¸€ä¸ªå­—å…¸ï¼Œé”®å¯¹åº”äºå‚æ•°åç§°ï¼Œå€¼å¯¹åº”äºè¯·æ±‚çš„å€¼ã€‚
"""

prompt = ChatPromptTemplate.from_messages(
    [("system", system_prompt), ("user", "{input}")]
)
```


```python
chain = prompt | model
message = chain.invoke({"input": "3 åŠ  1132 æ˜¯å¤šå°‘"})

# è®©æˆ‘ä»¬çœ‹çœ‹æ¨¡å‹çš„è¾“å‡º
# å¦‚æœæ¨¡å‹æ˜¯ä¸€ä¸ª LLMï¼ˆè€Œä¸æ˜¯èŠå¤©æ¨¡å‹ï¼‰ï¼Œè¾“å‡ºå°†æ˜¯ä¸€ä¸ªå­—ç¬¦ä¸²ã€‚
if isinstance(message, str):
    print(message)
else:  # å¦åˆ™å®ƒæ˜¯ä¸€ä¸ªèŠå¤©æ¨¡å‹
    print(message.content)
```
```output
{
    "name": "add",
    "arguments": {
        "x": 3,
        "y": 1132
    }
}
```

## æ·»åŠ è¾“å‡ºè§£æå™¨

æˆ‘ä»¬å°†ä½¿ç”¨ `JsonOutputParser` å°†æ¨¡å‹è¾“å‡ºè§£æä¸º JSONã€‚

```python
from langchain_core.output_parsers import JsonOutputParser

chain = prompt | model | JsonOutputParser()
chain.invoke({"input": "what's thirteen times 4"})
```

```output
{'name': 'multiply', 'arguments': {'x': 13.0, 'y': 4.0}}
```

:::important

ğŸ‰ å¤ªæ£’äº†ï¼ ğŸ‰ æˆ‘ä»¬ç°åœ¨å·²ç»æŒ‡ç¤ºæˆ‘ä»¬çš„æ¨¡å‹å¦‚ä½• **è¯·æ±‚** è°ƒç”¨ä¸€ä¸ªå·¥å…·ã€‚

ç°åœ¨ï¼Œè®©æˆ‘ä»¬åˆ›å»ºä¸€äº›é€»è¾‘æ¥å®é™…è¿è¡Œè¿™ä¸ªå·¥å…·ï¼ 
:::

## è°ƒç”¨å·¥å…· ğŸƒ

ç°åœ¨æ¨¡å‹å¯ä»¥è¯·æ±‚è°ƒç”¨å·¥å…·ï¼Œæˆ‘ä»¬éœ€è¦ç¼–å†™ä¸€ä¸ªå®é™…è°ƒç”¨å·¥å…·çš„å‡½æ•°ã€‚

è¯¥å‡½æ•°å°†æ ¹æ®åç§°é€‰æ‹©é€‚å½“çš„å·¥å…·ï¼Œå¹¶å°†æ¨¡å‹é€‰æ‹©çš„å‚æ•°ä¼ é€’ç»™å®ƒã€‚

```python
from typing import Any, Dict, Optional, TypedDict

from langchain_core.runnables import RunnableConfig


class ToolCallRequest(TypedDict):
    """ä¸€ä¸ªç±»å‹å­—å…¸ï¼Œæ˜¾ç¤ºä¼ å…¥ invoke_tool å‡½æ•°çš„è¾“å…¥ã€‚"""

    name: str
    arguments: Dict[str, Any]


def invoke_tool(
    tool_call_request: ToolCallRequest, config: Optional[RunnableConfig] = None
):
    """ä¸€ä¸ªå¯ä»¥ç”¨æ¥æ‰§è¡Œå·¥å…·è°ƒç”¨çš„å‡½æ•°ã€‚

    Args:
        tool_call_request: åŒ…å«é”® name å’Œ arguments çš„å­—å…¸ã€‚
            name å¿…é¡»ä¸ç°æœ‰å·¥å…·çš„åç§°åŒ¹é…ã€‚
            arguments æ˜¯è¯¥å·¥å…·çš„å‚æ•°ã€‚
        config: è¿™æ˜¯ LangChain ä½¿ç”¨çš„é…ç½®ä¿¡æ¯ï¼ŒåŒ…å«
            å›è°ƒã€å…ƒæ•°æ®ç­‰ã€‚è¯·å‚è§ LCEL æ–‡æ¡£ä¸­çš„ RunnableConfigã€‚

    Returns:
        è¯·æ±‚å·¥å…·çš„è¾“å‡º
    """
    tool_name_to_tool = {tool.name: tool for tool in tools}
    name = tool_call_request["name"]
    requested_tool = tool_name_to_tool[name]
    return requested_tool.invoke(tool_call_request["arguments"], config=config)
```

è®©æˆ‘ä»¬æµ‹è¯•ä¸€ä¸‹ ğŸ§ªï¼

```python
invoke_tool({"name": "multiply", "arguments": {"x": 3, "y": 5}})
```

```output
15.0
```

## æˆ‘ä»¬æ¥æ•´åˆä¸€ä¸‹

æˆ‘ä»¬å°†å…¶æ•´åˆæˆä¸€ä¸ªé“¾ï¼Œåˆ›å»ºä¸€ä¸ªå…·æœ‰åŠ æ³•å’Œä¹˜æ³•åŠŸèƒ½çš„è®¡ç®—å™¨ã€‚

```python
chain = prompt | model | JsonOutputParser() | invoke_tool
chain.invoke({"input": "what's thirteen times 4.14137281"})
```

```output
53.83784653
```

## è¿”å›å·¥å…·è¾“å…¥

è¿”å›å·¥å…·è¾“å‡ºæ—¶ï¼ŒåŒæ—¶è¿”å›å·¥å…·è¾“å…¥ä¹Ÿæ˜¯å¾ˆæœ‰å¸®åŠ©çš„ã€‚æˆ‘ä»¬å¯ä»¥é€šè¿‡ `RunnablePassthrough.assign` æ¥è½»æ¾å®ç°è¿™ä¸€ç‚¹ã€‚è¿™å°†è·å–ä¼ é€’ç»™ RunnablePassthrough ç»„ä»¶çš„è¾“å…¥ï¼ˆå‡è®¾ä¸ºå­—å…¸ï¼‰ï¼Œå¹¶åœ¨å…¶ä¸Šæ·»åŠ ä¸€ä¸ªé”®ï¼ŒåŒæ—¶ä»ç„¶ä¼ é€’è¾“å…¥ä¸­å½“å‰çš„æ‰€æœ‰å†…å®¹ï¼š

```python
from langchain_core.runnables import RunnablePassthrough

chain = (
    prompt | model | JsonOutputParser() | RunnablePassthrough.assign(output=invoke_tool)
)
chain.invoke({"input": "what's thirteen times 4.14137281"})
```

```output
{'name': 'multiply',
 'arguments': {'x': 13, 'y': 4.14137281},
 'output': 53.83784653}
```

## æ¥ä¸‹æ¥æ˜¯ä»€ä¹ˆï¼Ÿ

æœ¬æŒ‡å—å±•ç¤ºäº†å½“æ¨¡å‹æ­£ç¡®è¾“å‡ºæ‰€æœ‰æ‰€éœ€å·¥å…·ä¿¡æ¯æ—¶çš„â€œç†æƒ³è·¯å¾„â€ã€‚

å®é™…ä¸Šï¼Œå¦‚æœæ‚¨ä½¿ç”¨æ›´å¤æ‚çš„å·¥å…·ï¼Œæ‚¨å°†å¼€å§‹é‡åˆ°æ¨¡å‹çš„é”™è¯¯ï¼Œå°¤å…¶æ˜¯å¯¹äºé‚£äº›æ²¡æœ‰é’ˆå¯¹å·¥å…·è°ƒç”¨è¿›è¡Œå¾®è°ƒçš„æ¨¡å‹ä»¥åŠèƒ½åŠ›è¾ƒå¼±çš„æ¨¡å‹ã€‚

æ‚¨éœ€è¦å‡†å¤‡å¥½æ·»åŠ ç­–ç•¥ä»¥æ”¹å–„æ¨¡å‹çš„è¾“å‡ºï¼›ä¾‹å¦‚ï¼š

1. æä¾›å°‘é‡ç¤ºä¾‹ã€‚
2. æ·»åŠ é”™è¯¯å¤„ç†ï¼ˆä¾‹å¦‚ï¼Œæ•è·å¼‚å¸¸å¹¶å°†å…¶åé¦ˆç»™LLMï¼Œè¦æ±‚å…¶çº æ­£ä¹‹å‰çš„è¾“å‡ºï¼‰ã€‚