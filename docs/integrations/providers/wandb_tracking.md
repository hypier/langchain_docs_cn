---
custom_edit_url: https://github.com/langchain-ai/langchain/edit/master/docs/docs/integrations/providers/wandb_tracking.ipynb
---

# Weights & Biases

æœ¬ç¬”è®°æœ¬ä»‹ç»äº†å¦‚ä½•å°†æ‚¨çš„ LangChain å®éªŒè·Ÿè¸ªåˆ°ä¸€ä¸ªé›†ä¸­åŒ–çš„æƒé‡ä¸åå·®ä»ªè¡¨æ¿ä¸­ã€‚è¦äº†è§£æ›´å¤šå…³äºæç¤ºå·¥ç¨‹å’Œå›è°ƒçš„ä¿¡æ¯ï¼Œè¯·å‚è€ƒæ­¤æŠ¥å‘Šï¼Œè¯¥æŠ¥å‘Šè§£é‡Šäº†è¿™ä¸¤è€…ä»¥åŠæ‚¨å¯ä»¥æœŸå¾…çœ‹åˆ°çš„ç»“æœä»ªè¡¨æ¿ã€‚

<a href="https://colab.research.google.com/drive/1DXH4beT4HFaRKy_Vm4PoxhXVDRf7Ym8L?usp=sharing" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="åœ¨ Colab ä¸­æ‰“å¼€"/></a>

[æŸ¥çœ‹æŠ¥å‘Š](https://wandb.ai/a-sh0ts/langchain_callback_demo/reports/Prompt-Engineering-LLMs-with-LangChain-and-W-B--VmlldzozNjk1NTUw#ğŸ‘‹-å¦‚ä½•åœ¨langchainä¸­æ„å»ºå›è°ƒä»¥æ›´å¥½åœ°è¿›è¡Œæç¤ºå·¥ç¨‹)

**æ³¨æ„**ï¼š_`WandbCallbackHandler` æ­£åœ¨è¢«å¼ƒç”¨ï¼Œå–è€Œä»£ä¹‹çš„æ˜¯ `WandbTracer`_ã€‚åœ¨æœªæ¥è¯·ä½¿ç”¨ `WandbTracer`ï¼Œå› ä¸ºå®ƒæ›´çµæ´»å¹¶å…è®¸æ›´ç»†ç²’åº¦çš„æ—¥å¿—è®°å½•ã€‚è¦äº†è§£æ›´å¤šå…³äº `WandbTracer` çš„ä¿¡æ¯ï¼Œè¯·å‚è€ƒ [agent_with_wandb_tracing](/docs/integrations/providers/wandb_tracing) ç¬”è®°æœ¬æˆ–ä½¿ç”¨ä»¥ä¸‹ [colab ç¬”è®°æœ¬](http://wandb.me/prompts-quickstart)ã€‚è¦äº†è§£æ›´å¤šå…³äºæƒé‡ä¸åå·®æç¤ºçš„ä¿¡æ¯ï¼Œè¯·å‚è€ƒä»¥ä¸‹ [æç¤ºæ–‡æ¡£](https://docs.wandb.ai/guides/prompts)ã€‚

```python
%pip install --upgrade --quiet  wandb
%pip install --upgrade --quiet  pandas
%pip install --upgrade --quiet  textstat
%pip install --upgrade --quiet  spacy
!python -m spacy download en_core_web_sm
```

```python
import os

os.environ["WANDB_API_KEY"] = ""
# os.environ["OPENAI_API_KEY"] = ""
# os.environ["SERPAPI_API_KEY"] = ""
```

```python
from datetime import datetime

from langchain_community.callbacks import WandbCallbackHandler
from langchain_core.callbacks import StdOutCallbackHandler
from langchain_openai import OpenAI
```

```
è®°å½•åˆ°æƒé‡ä¸åå·®çš„å›è°ƒå¤„ç†å™¨ã€‚

å‚æ•°ï¼š
    job_type (str): ä½œä¸šç±»å‹ã€‚
    project (str): è¦è®°å½•çš„é¡¹ç›®ã€‚
    entity (str): è¦è®°å½•çš„å®ä½“ã€‚
    tags (list): è¦è®°å½•çš„æ ‡ç­¾ã€‚
    group (str): è¦è®°å½•çš„ç»„ã€‚
    name (str): è¿è¡Œçš„åç§°ã€‚
    notes (str): è¦è®°å½•çš„å¤‡æ³¨ã€‚
    visualize (bool): æ˜¯å¦å¯è§†åŒ–è¿è¡Œã€‚
    complexity_metrics (bool): æ˜¯å¦è®°å½•å¤æ‚æ€§æŒ‡æ ‡ã€‚
    stream_logs (bool): æ˜¯å¦å°†å›è°ƒæ“ä½œæµå¼ä¼ è¾“åˆ° W&Bã€‚
```

```
WandbCallbackHandler(...) çš„é»˜è®¤å€¼

visualize: bool = False,
complexity_metrics: bool = False,
stream_logs: bool = False,
```

æ³¨æ„ï¼šå¯¹äºæµ‹è¯•å·¥ä½œæµï¼Œæˆ‘ä»¬åŸºäº textstat è¿›è¡Œäº†é»˜è®¤åˆ†æï¼ŒåŸºäº spacy è¿›è¡Œäº†å¯è§†åŒ–ã€‚

```python
"""ä¸»å‡½æ•°ã€‚

æ­¤å‡½æ•°ç”¨äºå°è¯•å›è°ƒå¤„ç†å™¨ã€‚
åœºæ™¯ï¼š
1. OpenAI LLM
2. åŒ…å«å¤šä¸ªå­é“¾çš„é“¾ï¼Œè¿›è¡Œå¤šæ¬¡ç”Ÿæˆ
3. å¸¦å·¥å…·çš„ä»£ç†
"""
session_group = datetime.now().strftime("%m.%d.%Y_%H.%M.%S")
wandb_callback = WandbCallbackHandler(
    job_type="inference",
    project="langchain_callback_demo",
    group=f"minimal_{session_group}",
    name="llm",
    tags=["test"],
)
callbacks = [StdOutCallbackHandler(), wandb_callback]
llm = OpenAI(temperature=0, callbacks=callbacks)
```


```
# WandbCallbackHandler.flush_tracker(...) çš„é»˜è®¤å€¼

reset: bool = True,
finish: bool = False,
```

`flush_tracker` å‡½æ•°ç”¨äºå°† LangChain ä¼šè¯è®°å½•åˆ°æƒé‡ä¸åå·®ä¸­ã€‚å®ƒæ¥å— LangChain æ¨¡å—æˆ–ä»£ç†ï¼Œå¹¶è‡³å°‘è®°å½•æç¤ºå’Œç”Ÿæˆï¼Œä»¥åŠ LangChain æ¨¡å—çš„åºåˆ—åŒ–å½¢å¼åˆ°æŒ‡å®šçš„æƒé‡ä¸åå·®é¡¹ç›®ä¸­ã€‚é»˜è®¤æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬é‡ç½®ä¼šè¯ï¼Œè€Œä¸æ˜¯ç›´æ¥ç»“æŸä¼šè¯ã€‚

```python
# åœºæ™¯ 1 - LLM
llm_result = llm.generate(["å‘Šè¯‰æˆ‘ä¸€ä¸ªç¬‘è¯", "ç»™æˆ‘ä¸€é¦–è¯—"] * 3)
wandb_callback.flush_tracker(llm, name="simple_sequential")
```



```python
from langchain.chains import LLMChain
from langchain_core.prompts import PromptTemplate
```

```python
# åœºæ™¯ 2 - é“¾
template = """æ‚¨æ˜¯ä¸€ä½å‰§ä½œå®¶ã€‚ç»™å®šå‰§æœ¬çš„æ ‡é¢˜ï¼Œæ‚¨çš„å·¥ä½œæ˜¯ä¸ºè¯¥æ ‡é¢˜å†™ä¸€ä¸ªæ¦‚è¦ã€‚
æ ‡é¢˜: {title}
å‰§ä½œå®¶: è¿™æ˜¯ä¸Šè¿°å‰§æœ¬çš„æ¦‚è¦:"""
prompt_template = PromptTemplate(input_variables=["title"], template=template)
synopsis_chain = LLMChain(llm=llm, prompt=prompt_template, callbacks=callbacks)

test_prompts = [
    {
        "title": "å…³äºæ¨åŠ¨æ¸¸æˆè®¾è®¡è¾¹ç•Œçš„ä¼˜ç§€è§†é¢‘æ¸¸æˆçš„çºªå½•ç‰‡"
    },
    {"title": "å¯å¡å› ç†Š vs æµ·æ´›å› ç‹¼"},
    {"title": "æœ€ä½³çš„ MLOps å·¥å…·"},
]
synopsis_chain.apply(test_prompts)
wandb_callback.flush_tracker(synopsis_chain, name="agent")
```



```python
from langchain.agents import AgentType, initialize_agent, load_tools
```

```python
# åœºæ™¯ 3 - å¸¦å·¥å…·çš„ä»£ç†
tools = load_tools(["serpapi", "llm-math"], llm=llm)
agent = initialize_agent(
    tools,
    llm,
    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,
)
agent.run(
    "è°æ˜¯è±æ˜‚çº³å¤šÂ·è¿ªå¡æ™®é‡Œå¥¥çš„å¥³å‹ï¼Ÿå¥¹å½“å‰çš„å¹´é¾„çš„ 0.43 æ¬¡æ–¹æ˜¯å¤šå°‘ï¼Ÿ",
    callbacks=callbacks,
)
wandb_callback.flush_tracker(agent, reset=False, finish=True)
```
