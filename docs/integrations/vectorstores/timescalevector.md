---
custom_edit_url: https://github.com/langchain-ai/langchain/edit/master/docs/docs/integrations/vectorstores/timescalevector.ipynb
---

# Timescale Vector (Postgres)

>[Timescale Vector](https://www.timescale.com/ai?utm_campaign=vectorlaunch&utm_source=langchain&utm_medium=referral) æ˜¯ç”¨äº AI åº”ç”¨çš„ `PostgreSQL++` å‘é‡æ•°æ®åº“ã€‚

æœ¬ç¬”è®°æœ¬å±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨ Postgres å‘é‡æ•°æ®åº“ `Timescale Vector`ã€‚æ‚¨å°†å­¦ä¹ å¦‚ä½•ä½¿ç”¨ TimescaleVector è¿›è¡Œ (1) è¯­ä¹‰æœç´¢ï¼Œ(2) åŸºäºæ—¶é—´çš„å‘é‡æœç´¢ï¼Œ(3) è‡ªæˆ‘æŸ¥è¯¢ï¼Œä»¥åŠ (4) å¦‚ä½•åˆ›å»ºç´¢å¼•ä»¥åŠ é€ŸæŸ¥è¯¢ã€‚

## ä»€ä¹ˆæ˜¯ Timescale Vectorï¼Ÿ

`Timescale Vector` ä½¿æ‚¨èƒ½å¤Ÿåœ¨ `PostgreSQL` ä¸­é«˜æ•ˆå­˜å‚¨å’ŒæŸ¥è¯¢æ•°ç™¾ä¸‡ä¸ªå‘é‡åµŒå…¥ã€‚
- é€šè¿‡å— `DiskANN` å¯å‘çš„ç´¢å¼•ç®—æ³•ï¼Œå¢å¼ºäº† `pgvector`ï¼Œåœ¨ 100M+ å‘é‡ä¸Šå®ç°æ›´å¿«å’Œæ›´å‡†ç¡®çš„ç›¸ä¼¼æ€§æœç´¢ã€‚
- é€šè¿‡è‡ªåŠ¨æ—¶é—´åˆ†åŒºå’Œç´¢å¼•ï¼Œæ”¯æŒå¿«é€Ÿçš„åŸºäºæ—¶é—´çš„å‘é‡æœç´¢ã€‚
- æä¾›ç†Ÿæ‚‰çš„ SQL æ¥å£ï¼Œç”¨äºæŸ¥è¯¢å‘é‡åµŒå…¥å’Œå…³ç³»æ•°æ®ã€‚

`Timescale Vector` æ˜¯é€‚ç”¨äº AI çš„äº‘ `PostgreSQL`ï¼Œå¯ä»¥éšç€æ‚¨ä» POC åˆ°ç”Ÿäº§çš„æ‰©å±•è€Œæ‰©å±•ï¼š
- é€šè¿‡ä½¿æ‚¨èƒ½å¤Ÿåœ¨å•ä¸ªæ•°æ®åº“ä¸­å­˜å‚¨å…³ç³»å…ƒæ•°æ®ã€å‘é‡åµŒå…¥å’Œæ—¶é—´åºåˆ—æ•°æ®ï¼Œç®€åŒ–æ“ä½œã€‚
- å—ç›Šäºåšå¦‚ç£çŸ³çš„ PostgreSQL åŸºç¡€ï¼Œå…·æœ‰ä¼ä¸šçº§åŠŸèƒ½ï¼Œå¦‚æµå¼å¤‡ä»½å’Œå¤åˆ¶ã€é«˜å¯ç”¨æ€§å’Œè¡Œçº§å®‰å…¨æ€§ã€‚
- æä¾›æ— å¿§ä½“éªŒï¼Œå…·å¤‡ä¼ä¸šçº§å®‰å…¨æ€§å’Œåˆè§„æ€§ã€‚

## å¦‚ä½•è®¿é—® Timescale Vector

`Timescale Vector` å¯åœ¨ [Timescale](https://www.timescale.com/ai?utm_campaign=vectorlaunch&utm_source=langchain&utm_medium=referral) ä¸Šä½¿ç”¨ï¼Œè¿™æ˜¯ä¸€ä¸ªäº‘ PostgreSQL å¹³å°ã€‚ï¼ˆç›®å‰æ²¡æœ‰è‡ªæ‰˜ç®¡ç‰ˆæœ¬ã€‚ï¼‰

LangChain ç”¨æˆ·å¯ä»¥è·å¾— 90 å¤©çš„ Timescale Vector å…è´¹è¯•ç”¨ã€‚
- è¦å¼€å§‹ï¼Œè¯· [æ³¨å†Œ](https://console.cloud.timescale.com/signup?utm_campaign=vectorlaunch&utm_source=langchain&utm_medium=referral) Timescaleï¼Œåˆ›å»ºä¸€ä¸ªæ–°æ•°æ®åº“å¹¶æŒ‰ç…§æ­¤ç¬”è®°æœ¬æ“ä½œï¼
- æœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯å’Œæ€§èƒ½åŸºå‡†ï¼Œè¯·å‚é˜… [Timescale Vector è§£é‡Šåšå®¢](https://www.timescale.com/blog/how-we-made-postgresql-the-best-vector-database/?utm_campaign=vectorlaunch&utm_source=langchain&utm_medium=referral)ã€‚
- æœ‰å…³åœ¨ Python ä¸­ä½¿ç”¨ Timescale Vector çš„æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚è§ [å®‰è£…è¯´æ˜](https://github.com/timescale/python-vector)ã€‚

## è®¾ç½®

æŒ‰ç…§ä»¥ä¸‹æ­¥éª¤å‡†å¤‡å¥½ä»¥è·Ÿéšæœ¬æ•™ç¨‹ã€‚

```python
# Pip install necessary packages
%pip install --upgrade --quiet  timescale-vector
%pip install --upgrade --quiet  langchain-openai langchain-community
%pip install --upgrade --quiet  tiktoken
```

åœ¨æ­¤ç¤ºä¾‹ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ `OpenAIEmbeddings`ï¼Œå› æ­¤è¯·åŠ è½½æ‚¨çš„ OpenAI API å¯†é’¥ã€‚

```python
import os

# Run export OPENAI_API_KEY=sk-YOUR_OPENAI_API_KEY...
# Get openAI api key by reading local .env file
from dotenv import find_dotenv, load_dotenv

_ = load_dotenv(find_dotenv())
OPENAI_API_KEY = os.environ["OPENAI_API_KEY"]
```

```python
# Get the API key and save it as an environment variable
# import os
# import getpass
# os.environ["OPENAI_API_KEY"] = getpass.getpass("OpenAI API Key:")
```

```python
from typing import Tuple
```

æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°†å¯¼å…¥æ‰€éœ€çš„ Python åº“å’Œ LangChain åº“ã€‚è¯·æ³¨æ„ï¼Œæˆ‘ä»¬å¯¼å…¥ `timescale-vector` åº“ä»¥åŠ TimescaleVector LangChain å‘é‡å­˜å‚¨ã€‚

```python
from datetime import datetime, timedelta

from langchain_community.document_loaders import TextLoader
from langchain_community.document_loaders.json_loader import JSONLoader
from langchain_community.vectorstores.timescalevector import TimescaleVector
from langchain_core.documents import Document
from langchain_openai import OpenAIEmbeddings
from langchain_text_splitters import CharacterTextSplitter
```

## 1. ä½¿ç”¨æ¬§å‡ é‡Œå¾—è·ç¦»è¿›è¡Œç›¸ä¼¼æ€§æœç´¢ï¼ˆé»˜è®¤ï¼‰

é¦–å…ˆï¼Œæˆ‘ä»¬å°†æŸ¥çœ‹ä¸€ä¸ªåœ¨å›½æƒ…å’¨æ–‡æ¼”è®²ä¸­è¿›è¡Œç›¸ä¼¼æ€§æœç´¢æŸ¥è¯¢çš„ç¤ºä¾‹ï¼Œä»¥æŸ¥æ‰¾ä¸ç»™å®šæŸ¥è¯¢å¥å­æœ€ç›¸ä¼¼çš„å¥å­ã€‚æˆ‘ä»¬å°†ä½¿ç”¨ [æ¬§å‡ é‡Œå¾—è·ç¦»](https://en.wikipedia.org/wiki/Euclidean_distance) ä½œä¸ºæˆ‘ä»¬çš„ç›¸ä¼¼æ€§åº¦é‡æ ‡å‡†ã€‚

```python
# Load the text and split it into chunks
loader = TextLoader("../../../extras/modules/state_of_the_union.txt")
documents = loader.load()
text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)
docs = text_splitter.split_documents(documents)

embeddings = OpenAIEmbeddings()
```

æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°†åŠ è½½ Timescale æ•°æ®åº“çš„æœåŠ¡ URLã€‚

å¦‚æœæ‚¨è¿˜æ²¡æœ‰ï¼Œè¯· [æ³¨å†Œ Timescale](https://console.cloud.timescale.com/signup?utm_campaign=vectorlaunch&utm_source=langchain&utm_medium=referral)ï¼Œå¹¶åˆ›å»ºä¸€ä¸ªæ–°æ•°æ®åº“ã€‚

ç„¶åï¼Œè¦è¿æ¥åˆ°æ‚¨çš„ PostgreSQL æ•°æ®åº“ï¼Œæ‚¨éœ€è¦æœåŠ¡ URIï¼Œè¯¥ URI å¯ä»¥åœ¨åˆ›å»ºæ–°æ•°æ®åº“åä¸‹è½½çš„å¤‡å¿˜å•æˆ– `.env` æ–‡ä»¶ä¸­æ‰¾åˆ°ã€‚

URI çš„æ ¼å¼å¦‚ä¸‹ï¼š`postgres://tsdbadmin:<password>@<id>.tsdb.cloud.timescale.com:<port>/tsdb?sslmode=require`ã€‚

```python
# Timescale Vector needs the service url to your cloud database. You can see this as soon as you create the
# service in the cloud UI or in your credentials.sql file
SERVICE_URL = os.environ["TIMESCALE_SERVICE_URL"]

# Specify directly if testing
# SERVICE_URL = "postgres://tsdbadmin:<password>@<id>.tsdb.cloud.timescale.com:<port>/tsdb?sslmode=require"

# # You can get also it from an environment variables. We suggest using a .env file.
# import os
# SERVICE_URL = os.environ.get("TIMESCALE_SERVICE_URL", "")
```

æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬åˆ›å»ºä¸€ä¸ª TimescaleVector å‘é‡å­˜å‚¨ã€‚æˆ‘ä»¬æŒ‡å®šä¸€ä¸ªé›†åˆåç§°ï¼Œè¯¥åç§°å°†æ˜¯æˆ‘ä»¬æ•°æ®å­˜å‚¨çš„è¡¨åã€‚

æ³¨æ„ï¼šåœ¨åˆ›å»º TimescaleVector çš„æ–°å®ä¾‹æ—¶ï¼ŒTimescaleVector æ¨¡å—å°†å°è¯•åˆ›å»ºä¸€ä¸ªä¸é›†åˆåç§°ç›¸åŒçš„è¡¨ã€‚å› æ­¤ï¼Œè¯·ç¡®ä¿é›†åˆåç§°æ˜¯å”¯ä¸€çš„ï¼ˆå³å®ƒä¸å­˜åœ¨ï¼‰ã€‚

```python
# The TimescaleVector Module will create a table with the name of the collection.
COLLECTION_NAME = "state_of_the_union_test"

# Create a Timescale Vector instance from the collection of documents
db = TimescaleVector.from_documents(
    embedding=embeddings,
    documents=docs,
    collection_name=COLLECTION_NAME,
    service_url=SERVICE_URL,
)
```

ç°åœ¨æˆ‘ä»¬å·²ç»åŠ è½½äº†æ•°æ®ï¼Œå¯ä»¥è¿›è¡Œç›¸ä¼¼æ€§æœç´¢ã€‚

```python
query = "What did the president say about Ketanji Brown Jackson"
docs_with_score = db.similarity_search_with_score(query)
```

```python
for doc, score in docs_with_score:
    print("-" * 80)
    print("Score: ", score)
    print(doc.page_content)
    print("-" * 80)
```

### ä½¿ç”¨ Timescale Vector ä½œä¸ºæ£€ç´¢å™¨
åœ¨åˆå§‹åŒ– TimescaleVector å­˜å‚¨åï¼Œæ‚¨å¯ä»¥å°†å…¶ç”¨ä½œ [æ£€ç´¢å™¨](/docs/how_to#retrievers)ã€‚

```python
# Use TimescaleVector as a retriever
retriever = db.as_retriever()
```

```python
print(retriever)
```
```output
tags=['TimescaleVector', 'OpenAIEmbeddings'] metadata=None vectorstore=<langchain_community.vectorstores.timescalevector.TimescaleVector object at 0x10fc8d070> search_type='similarity' search_kwargs={}
```
è®©æˆ‘ä»¬çœ‹ä¸€ä¸ªä½¿ç”¨ Timescale Vector ä½œä¸ºæ£€ç´¢å™¨çš„ç¤ºä¾‹ï¼Œç»“åˆ RetrievalQA é“¾å’Œå†…å®¹æ–‡æ¡£é“¾ã€‚

åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œæˆ‘ä»¬å°†æå‡ºä¸ä¸Šé¢ç›¸åŒçš„é—®é¢˜ï¼Œä½†è¿™æ¬¡æˆ‘ä»¬ä¼šå°†ä» Timescale Vector è¿”å›çš„ç›¸å…³æ–‡æ¡£ä¼ é€’ç»™ LLMï¼Œä»¥ç”¨ä½œå›ç­”æˆ‘ä»¬é—®é¢˜çš„ä¸Šä¸‹æ–‡ã€‚

é¦–å…ˆï¼Œæˆ‘ä»¬å°†åˆ›å»ºæˆ‘ä»¬çš„å†…å®¹é“¾ï¼š

```python
# Initialize GPT3.5 model
from langchain_openai import ChatOpenAI

llm = ChatOpenAI(temperature=0.1, model="gpt-3.5-turbo-16k")

# Initialize a RetrievalQA class from a stuff chain
from langchain.chains import RetrievalQA

qa_stuff = RetrievalQA.from_chain_type(
    llm=llm,
    chain_type="stuff",
    retriever=retriever,
    verbose=True,
)
```

```python
query = "What did the president say about Ketanji Brown Jackson?"
response = qa_stuff.run(query)
```
```output


[1m> Entering new RetrievalQA chain...[0m

[1m> Finished chain.[0m
```

```python
print(response)
```
```output
æ€»ç»Ÿè¡¨ç¤ºï¼Œä»–æåäº†å·¡å›ä¸Šè¯‰æ³•é™¢æ³•å®˜ Ketanji Brown Jacksonï¼Œå¥¹æ˜¯æˆ‘ä»¬å›½å®¶é¡¶å°–çš„æ³•å¾‹äººæ‰ä¹‹ä¸€ï¼Œå°†ç»§ç»­å¸ƒé›·è€¶æ³•å®˜çš„å“è¶Šé—äº§ã€‚ä»–è¿˜æåˆ°ï¼Œè‡ªå¥¹è¢«æåä»¥æ¥ï¼Œå¥¹å¾—åˆ°äº†åŒ…æ‹¬è­¦å¯Ÿå…„å¼Ÿä¼šå’Œç”±æ°‘ä¸»å…šå’Œå…±å’Œå…šä»»å‘½çš„å‰æ³•å®˜åœ¨å†…çš„å„ä¸ªå›¢ä½“çš„å¹¿æ³›æ”¯æŒã€‚
```

## 2. åŸºäºæ—¶é—´è¿‡æ»¤çš„ç›¸ä¼¼æ€§æœç´¢

Timescale Vector çš„ä¸€ä¸ªå…³é”®ç”¨ä¾‹æ˜¯é«˜æ•ˆçš„åŸºäºæ—¶é—´çš„å‘é‡æœç´¢ã€‚Timescale Vector é€šè¿‡æŒ‰æ—¶é—´è‡ªåŠ¨å¯¹å‘é‡ï¼ˆåŠç›¸å…³å…ƒæ•°æ®ï¼‰è¿›è¡Œåˆ†åŒºæ¥å®ç°è¿™ä¸€ç‚¹ã€‚è¿™ä½¿æ‚¨èƒ½å¤Ÿé€šè¿‡ä¸æŸ¥è¯¢å‘é‡çš„ç›¸ä¼¼æ€§å’Œæ—¶é—´é«˜æ•ˆåœ°æŸ¥è¯¢å‘é‡ã€‚

åŸºäºæ—¶é—´çš„å‘é‡æœç´¢åŠŸèƒ½å¯¹ä»¥ä¸‹åº”ç”¨ç¨‹åºéå¸¸æœ‰å¸®åŠ©ï¼š
- å­˜å‚¨å’Œæ£€ç´¢ LLM å“åº”å†å²ï¼ˆä¾‹å¦‚èŠå¤©æœºå™¨äººï¼‰
- æŸ¥æ‰¾ä¸æŸ¥è¯¢å‘é‡ç›¸ä¼¼çš„æœ€æ–°åµŒå…¥ï¼ˆä¾‹å¦‚æœ€è¿‘çš„æ–°é—»ï¼‰
- å°†ç›¸ä¼¼æ€§æœç´¢é™åˆ¶åœ¨ç›¸å…³çš„æ—¶é—´èŒƒå›´å†…ï¼ˆä¾‹å¦‚å¯¹çŸ¥è¯†åº“æå‡ºåŸºäºæ—¶é—´çš„é—®é¢˜ï¼‰

ä¸ºäº†è¯´æ˜å¦‚ä½•ä½¿ç”¨ TimescaleVector çš„åŸºäºæ—¶é—´çš„å‘é‡æœç´¢åŠŸèƒ½ï¼Œæˆ‘ä»¬å°†è¯¢é—®æœ‰å…³ TimescaleDB çš„ git æ—¥å¿—å†å²çš„é—®é¢˜ã€‚æˆ‘ä»¬å°†æ¼”ç¤ºå¦‚ä½•æ·»åŠ å¸¦æœ‰æ—¶é—´æˆ³çš„ uuid çš„æ–‡æ¡£ï¼Œä»¥åŠå¦‚ä½•ä½¿ç”¨æ—¶é—´èŒƒå›´è¿‡æ»¤å™¨è¿è¡Œç›¸ä¼¼æ€§æœç´¢ã€‚

### ä» git log JSON ä¸­æå–å†…å®¹å’Œå…ƒæ•°æ®
é¦–å…ˆï¼Œè®©æˆ‘ä»¬å°† git log æ•°æ®åŠ è½½åˆ°åä¸º `timescale_commits` çš„ PostgreSQL æ•°æ®åº“ä¸­çš„æ–°é›†åˆä¸­ã€‚

æˆ‘ä»¬å°†å®šä¹‰ä¸€ä¸ªè¾…åŠ©å‡½æ•°ï¼Œæ ¹æ®æ–‡æ¡£çš„æ—¶é—´æˆ³ä¸ºæ–‡æ¡£å’Œç›¸å…³çš„å‘é‡åµŒå…¥åˆ›å»ºä¸€ä¸ª uuidã€‚æˆ‘ä»¬å°†ä½¿ç”¨æ­¤å‡½æ•°ä¸ºæ¯ä¸ª git log æ¡ç›®åˆ›å»ºä¸€ä¸ª uuidã€‚

é‡è¦æç¤ºï¼šå¦‚æœæ‚¨æ­£åœ¨å¤„ç†æ–‡æ¡£å¹¶å¸Œæœ›å°†å½“å‰æ—¥æœŸå’Œæ—¶é—´ä¸å‘é‡å…³è”ä»¥è¿›è¡ŒåŸºäºæ—¶é—´çš„æœç´¢ï¼Œå¯ä»¥è·³è¿‡æ­¤æ­¥éª¤ã€‚é»˜è®¤æƒ…å†µä¸‹ï¼Œæ–‡æ¡£è¢«æ‘„å–æ—¶å°†è‡ªåŠ¨ç”Ÿæˆä¸€ä¸ª uuidã€‚

```python
from timescale_vector import client


# Function to take in a date string in the past and return a uuid v1
def create_uuid(date_string: str):
    if date_string is None:
        return None
    time_format = "%a %b %d %H:%M:%S %Y %z"
    datetime_obj = datetime.strptime(date_string, time_format)
    uuid = client.uuid_from_time(datetime_obj)
    return str(uuid)
```

æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°†å®šä¹‰ä¸€ä¸ªå…ƒæ•°æ®å‡½æ•°ï¼Œä» JSON è®°å½•ä¸­æå–ç›¸å…³çš„å…ƒæ•°æ®ã€‚æˆ‘ä»¬å°†æŠŠè¿™ä¸ªå‡½æ•°ä¼ é€’ç»™ JSONLoaderã€‚æœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚è§ [JSON æ–‡æ¡£åŠ è½½å™¨æ–‡æ¡£](/docs/how_to/document_loader_json)ã€‚

```python
# Helper function to split name and email given an author string consisting of Name Lastname <email>
def split_name(input_string: str) -> Tuple[str, str]:
    if input_string is None:
        return None, None
    start = input_string.find("<")
    end = input_string.find(">")
    name = input_string[:start].strip()
    email = input_string[start + 1 : end].strip()
    return name, email


# Helper function to transform a date string into a timestamp_tz string
def create_date(input_string: str) -> datetime:
    if input_string is None:
        return None
    # Define a dictionary to map month abbreviations to their numerical equivalents
    month_dict = {
        "Jan": "01",
        "Feb": "02",
        "Mar": "03",
        "Apr": "04",
        "May": "05",
        "Jun": "06",
        "Jul": "07",
        "Aug": "08",
        "Sep": "09",
        "Oct": "10",
        "Nov": "11",
        "Dec": "12",
    }

    # Split the input string into its components
    components = input_string.split()
    # Extract relevant information
    day = components[2]
    month = month_dict[components[1]]
    year = components[4]
    time = components[3]
    timezone_offset_minutes = int(components[5])  # Convert the offset to minutes
    timezone_hours = timezone_offset_minutes // 60  # Calculate the hours
    timezone_minutes = timezone_offset_minutes % 60  # Calculate the remaining minutes
    # Create a formatted string for the timestamptz in PostgreSQL format
    timestamp_tz_str = (
        f"{year}-{month}-{day} {time}+{timezone_hours:02}{timezone_minutes:02}"
    )
    return timestamp_tz_str


# Metadata extraction function to extract metadata from a JSON record
def extract_metadata(record: dict, metadata: dict) -> dict:
    record_name, record_email = split_name(record["author"])
    metadata["id"] = create_uuid(record["date"])
    metadata["date"] = create_date(record["date"])
    metadata["author_name"] = record_name
    metadata["author_email"] = record_email
    metadata["commit_hash"] = record["commit"]
    return metadata
```

æ¥ä¸‹æ¥ï¼Œæ‚¨éœ€è¦ [ä¸‹è½½ç¤ºä¾‹æ•°æ®é›†](https://s3.amazonaws.com/assets.timescale.com/ai/ts_git_log.json) å¹¶å°†å…¶æ”¾åœ¨ä¸æ­¤ç¬”è®°æœ¬ç›¸åŒçš„ç›®å½•ä¸­ã€‚

æ‚¨å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤ï¼š

```python
# Download the file using curl and save it as commit_history.csv
# Note: Execute this command in your terminal, in the same directory as the notebook
!curl -O https://s3.amazonaws.com/assets.timescale.com/ai/ts_git_log.json
```

æœ€åï¼Œæˆ‘ä»¬å¯ä»¥åˆå§‹åŒ– JSON åŠ è½½å™¨ä»¥è§£æ JSON è®°å½•ã€‚æˆ‘ä»¬è¿˜åˆ é™¤ç©ºè®°å½•ä»¥ç®€åŒ–æ“ä½œã€‚

```python
# Define path to the JSON file relative to this notebook
# Change this to the path to your JSON file
FILE_PATH = "../../../../../ts_git_log.json"

# Load data from JSON file and extract metadata
loader = JSONLoader(
    file_path=FILE_PATH,
    jq_schema=".commit_history[]",
    text_content=False,
    metadata_func=extract_metadata,
)
documents = loader.load()

# Remove documents with None dates
documents = [doc for doc in documents if doc.metadata["date"] is not None]
```

```python
print(documents[0])
```
```output
page_content='{"commit": "44e41c12ab25e36c202f58e068ced262eadc8d16", "author": "Lakshmi Narayanan Sreethar<lakshmi@timescale.com>", "date": "Tue Sep 5 21:03:21 2023 +0530", "change summary": "Fix segfault in set_integer_now_func", "change details": "When an invalid function oid is passed to set_integer_now_func, it finds out that the function oid is invalid but before throwing the error, it calls ReleaseSysCache on an invalid tuple causing a segfault. Fixed that by removing the invalid call to ReleaseSysCache.  Fixes #6037 "}' metadata={'source': '/Users/avtharsewrathan/sideprojects2023/timescaleai/tsv-langchain/ts_git_log.json', 'seq_num': 1, 'id': '8b407680-4c01-11ee-96a6-b82284ddccc6', 'date': '2023-09-5 21:03:21+0850', 'author_name': 'Lakshmi Narayanan Sreethar', 'author_email': 'lakshmi@timescale.com', 'commit_hash': '44e41c12ab25e36c202f58e068ced262eadc8d16'}
```

### å°†æ–‡æ¡£å’Œå…ƒæ•°æ®åŠ è½½åˆ° TimescaleVector å‘é‡å­˜å‚¨ä¸­
ç°åœ¨æˆ‘ä»¬å·²ç»å‡†å¤‡å¥½äº†æ–‡æ¡£ï¼Œè®©æˆ‘ä»¬å¤„ç†å®ƒä»¬å¹¶å°†å®ƒä»¬åŠå…¶å‘é‡åµŒå…¥è¡¨ç¤ºåŠ è½½åˆ°æˆ‘ä»¬çš„ TimescaleVector å‘é‡å­˜å‚¨ä¸­ã€‚

ç”±äºè¿™æ˜¯ä¸€ä¸ªæ¼”ç¤ºï¼Œæˆ‘ä»¬å°†åªåŠ è½½å‰ 500 æ¡è®°å½•ã€‚åœ¨å®é™…æ“ä½œä¸­ï¼Œæ‚¨å¯ä»¥åŠ è½½ä»»æ„æ•°é‡çš„è®°å½•ã€‚


```python
NUM_RECORDS = 500
documents = documents[:NUM_RECORDS]
```

ç„¶åï¼Œæˆ‘ä»¬ä½¿ç”¨ CharacterTextSplitter å°†æ–‡æ¡£æ‹†åˆ†æˆæ›´å°çš„å—ï¼Œä»¥ä¾¿äºåµŒå…¥ã€‚è¯·æ³¨æ„ï¼Œè¿™ä¸ªæ‹†åˆ†è¿‡ç¨‹ä¿ç•™äº†æ¯ä¸ªæ–‡æ¡£çš„å…ƒæ•°æ®ã€‚


```python
# Split the documents into chunks for embedding
text_splitter = CharacterTextSplitter(
    chunk_size=1000,
    chunk_overlap=200,
)
docs = text_splitter.split_documents(documents)
```

æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°†ä»å®Œæˆé¢„å¤„ç†çš„æ–‡æ¡£é›†åˆä¸­åˆ›å»ºä¸€ä¸ª Timescale Vector å®ä¾‹ã€‚

é¦–å…ˆï¼Œæˆ‘ä»¬å°†å®šä¹‰ä¸€ä¸ªé›†åˆåç§°ï¼Œè¿™å°†æ˜¯æˆ‘ä»¬åœ¨ PostgreSQL æ•°æ®åº“ä¸­çš„è¡¨åã€‚

æˆ‘ä»¬è¿˜å°†å®šä¹‰ä¸€ä¸ªæ—¶é—´å¢é‡ï¼Œè¯¥å¢é‡å°†ä¼ é€’ç»™ `time_partition_interval` å‚æ•°ï¼Œç”¨äºæŒ‰æ—¶é—´å¯¹æ•°æ®è¿›è¡Œåˆ†åŒºã€‚æ¯ä¸ªåˆ†åŒºå°†åŒ…å«æŒ‡å®šæ—¶é—´é•¿åº¦çš„æ•°æ®ã€‚ä¸ºäº†ç®€å•èµ·è§ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ 7 å¤©ï¼Œä½†æ‚¨å¯ä»¥é€‰æ‹©é€‚åˆæ‚¨ç”¨ä¾‹çš„ä»»ä½•å€¼â€”â€”ä¾‹å¦‚ï¼Œå¦‚æœæ‚¨é¢‘ç¹æŸ¥è¯¢æœ€è¿‘çš„å‘é‡ï¼Œæ‚¨å¯èƒ½å¸Œæœ›ä½¿ç”¨ 1 å¤©è¿™æ ·è¾ƒå°çš„æ—¶é—´å¢é‡ï¼Œæˆ–è€…å¦‚æœæ‚¨æŸ¥è¯¢è·¨è¶Šåå¹´çš„å‘é‡ï¼Œæ‚¨å¯èƒ½å¸Œæœ›ä½¿ç”¨ 6 ä¸ªæœˆæˆ– 1 å¹´è¿™æ ·è¾ƒå¤§çš„æ—¶é—´å¢é‡ã€‚

æœ€åï¼Œæˆ‘ä»¬å°†åˆ›å»º TimescaleVector å®ä¾‹ã€‚æˆ‘ä»¬æŒ‡å®š `ids` å‚æ•°ä¸ºæˆ‘ä»¬åœ¨ä¸Šè¿°é¢„å¤„ç†æ­¥éª¤ä¸­åˆ›å»ºçš„å…ƒæ•°æ®ä¸­çš„ `uuid` å­—æ®µã€‚æˆ‘ä»¬è¿™æ ·åšæ˜¯å› ä¸ºæˆ‘ä»¬å¸Œæœ› uuid çš„æ—¶é—´éƒ¨åˆ†åæ˜ è¿‡å»çš„æ—¥æœŸï¼ˆå³æäº¤æ—¶çš„æ—¥æœŸï¼‰ã€‚ä½†æ˜¯ï¼Œå¦‚æœæˆ‘ä»¬å¸Œæœ›å°†å½“å‰æ—¥æœŸå’Œæ—¶é—´ä¸æˆ‘ä»¬çš„æ–‡æ¡£ç›¸å…³è”ï¼Œæˆ‘ä»¬å¯ä»¥åˆ é™¤ id å‚æ•°ï¼Œuuid å°†è‡ªåŠ¨ä½¿ç”¨å½“å‰æ—¥æœŸå’Œæ—¶é—´åˆ›å»ºã€‚


```python
# Define collection name
COLLECTION_NAME = "timescale_commits"
embeddings = OpenAIEmbeddings()

# Create a Timescale Vector instance from the collection of documents
db = TimescaleVector.from_documents(
    embedding=embeddings,
    ids=[doc.metadata["id"] for doc in docs],
    documents=docs,
    collection_name=COLLECTION_NAME,
    service_url=SERVICE_URL,
    time_partition_interval=timedelta(days=7),
)
```

### æŒ‰æ—¶é—´å’Œç›¸ä¼¼æ€§æŸ¥è¯¢å‘é‡

ç°åœ¨æˆ‘ä»¬å·²ç»å°†æ–‡æ¡£åŠ è½½åˆ° TimescaleVector ä¸­ï¼Œå¯ä»¥é€šè¿‡æ—¶é—´å’Œç›¸ä¼¼æ€§å¯¹å…¶è¿›è¡ŒæŸ¥è¯¢ã€‚

TimescaleVector æä¾›äº†å¤šç§æ–¹æ³•ï¼Œé€šè¿‡æ—¶é—´è¿‡æ»¤è¿›è¡Œç›¸ä¼¼æ€§æœç´¢ã€‚

è®©æˆ‘ä»¬çœ‹çœ‹ä¸‹é¢çš„æ¯ç§æ–¹æ³•ï¼š


```python
# Time filter variables
start_dt = datetime(2023, 8, 1, 22, 10, 35)  # Start date = 1 August 2023, 22:10:35
end_dt = datetime(2023, 8, 30, 22, 10, 35)  # End date = 30 August 2023, 22:10:35
td = timedelta(days=7)  # Time delta = 7 days

query = "What's new with TimescaleDB functions?"
```

æ–¹æ³• 1ï¼šåœ¨æä¾›çš„å¼€å§‹æ—¥æœŸå’Œç»“æŸæ—¥æœŸä¹‹é—´è¿›è¡Œè¿‡æ»¤ã€‚



```python
# Method 1: Query for vectors between start_date and end_date
docs_with_score = db.similarity_search_with_score(
    query, start_date=start_dt, end_date=end_dt
)

for doc, score in docs_with_score:
    print("-" * 80)
    print("Score: ", score)
    print("Date: ", doc.metadata["date"])
    print(doc.page_content)
    print("-" * 80)
```

è¯·æ³¨æ„ï¼ŒæŸ¥è¯¢ä»…è¿”å›æŒ‡å®šæ—¥æœŸèŒƒå›´å†…çš„ç»“æœã€‚

æ–¹æ³• 2ï¼šåœ¨æä¾›çš„å¼€å§‹æ—¥æœŸå’Œä¹‹åçš„æ—¶é—´å·®å†…è¿›è¡Œè¿‡æ»¤ã€‚


```python
# Method 2: Query for vectors between start_dt and a time delta td later
# Most relevant vectors between 1 August and 7 days later
docs_with_score = db.similarity_search_with_score(
    query, start_date=start_dt, time_delta=td
)

for doc, score in docs_with_score:
    print("-" * 80)
    print("Score: ", score)
    print("Date: ", doc.metadata["date"])
    print(doc.page_content)
    print("-" * 80)
```

å†æ¬¡æ³¨æ„ï¼Œæˆ‘ä»¬åœ¨æŒ‡å®šçš„æ—¶é—´è¿‡æ»¤å†…å¾—åˆ°äº†ç»“æœï¼Œè¿™ä¸ä¹‹å‰çš„æŸ¥è¯¢ä¸åŒã€‚

æ–¹æ³• 3ï¼šåœ¨æä¾›çš„ç»“æŸæ—¥æœŸå’Œä¹‹å‰çš„æ—¶é—´å·®å†…è¿›è¡Œè¿‡æ»¤ã€‚


```python
# Method 3: Query for vectors between end_dt and a time delta td earlier
# Most relevant vectors between 30 August and 7 days earlier
docs_with_score = db.similarity_search_with_score(query, end_date=end_dt, time_delta=td)

for doc, score in docs_with_score:
    print("-" * 80)
    print("Score: ", score)
    print("Date: ", doc.metadata["date"])
    print(doc.page_content)
    print("-" * 80)
```

æ–¹æ³• 4ï¼šæˆ‘ä»¬è¿˜å¯ä»¥é€šè¿‡åœ¨æŸ¥è¯¢ä¸­ä»…æŒ‡å®šå¼€å§‹æ—¥æœŸæ¥è¿‡æ»¤æ‰€æœ‰ç»™å®šæ—¥æœŸä¹‹åçš„å‘é‡ã€‚

æ–¹æ³• 5ï¼šç±»ä¼¼åœ°ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡åœ¨æŸ¥è¯¢ä¸­ä»…æŒ‡å®šç»“æŸæ—¥æœŸæ¥è¿‡æ»¤æ‰€æœ‰ç»™å®šæ—¥æœŸä¹‹å‰çš„å‘é‡ã€‚


```python
# Method 4: Query all vectors after start_date
docs_with_score = db.similarity_search_with_score(query, start_date=start_dt)

for doc, score in docs_with_score:
    print("-" * 80)
    print("Score: ", score)
    print("Date: ", doc.metadata["date"])
    print(doc.page_content)
    print("-" * 80)
```


```python
# Method 5: Query all vectors before end_date
docs_with_score = db.similarity_search_with_score(query, end_date=end_dt)

for doc, score in docs_with_score:
    print("-" * 80)
    print("Score: ", score)
    print("Date: ", doc.metadata["date"])
    print(doc.page_content)
    print("-" * 80)
```

ä¸»è¦çš„ç»“è®ºæ˜¯ï¼Œåœ¨ä¸Šè¿°æ¯ä¸ªç»“æœä¸­ï¼Œä»…è¿”å›æŒ‡å®šæ—¶é—´èŒƒå›´å†…çš„å‘é‡ã€‚è¿™äº›æŸ¥è¯¢éå¸¸é«˜æ•ˆï¼Œå› ä¸ºå®ƒä»¬åªéœ€è¦æœç´¢ç›¸å…³çš„åˆ†åŒºã€‚

æˆ‘ä»¬è¿˜å¯ä»¥ä½¿ç”¨æ­¤åŠŸèƒ½è¿›è¡Œé—®ç­”ï¼Œåœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬å¸Œæœ›æ‰¾åˆ°æŒ‡å®šæ—¶é—´èŒƒå›´å†…æœ€ç›¸å…³çš„å‘é‡ï¼Œä»¥ç”¨ä½œå›ç­”é—®é¢˜çš„ä¸Šä¸‹æ–‡ã€‚è®©æˆ‘ä»¬çœ‹çœ‹ä¸‹é¢çš„ç¤ºä¾‹ï¼Œä½¿ç”¨ Timescale Vector ä½œä¸ºæ£€ç´¢å™¨ï¼š


```python
# Set timescale vector as a retriever and specify start and end dates via kwargs
retriever = db.as_retriever(search_kwargs={"start_date": start_dt, "end_date": end_dt})
```


```python
from langchain_openai import ChatOpenAI

llm = ChatOpenAI(temperature=0.1, model="gpt-3.5-turbo-16k")

from langchain.chains import RetrievalQA

qa_stuff = RetrievalQA.from_chain_type(
    llm=llm,
    chain_type="stuff",
    retriever=retriever,
    verbose=True,
)

query = (
    "What's new with the timescaledb functions? Tell me when these changes were made."
)
response = qa_stuff.run(query)
print(response)
```
```output


[1m> Entering new RetrievalQA chain...[0m

[1m> Finished chain.[0m
The following changes were made to the timescaledb functions:

1. "Add compatibility layer for _timescaledb_internal functions" - This change was made on Tue Aug 29 18:13:24 2023 +0200.
2. "Move functions to _timescaledb_functions schema" - This change was made on Sun Aug 20 22:47:10 2023 +0200.
3. "Move utility functions to _timescaledb_functions schema" - This change was made on Tue Aug 22 12:01:19 2023 +0200.
4. "Move partitioning functions to _timescaledb_functions schema" - This change was made on Tue Aug 29 10:49:47 2023 +0200.
```
è¯·æ³¨æ„ï¼ŒLLM ç”¨äºæ„æˆç­”æ¡ˆçš„ä¸Šä¸‹æ–‡ä»…æ¥è‡ªäºåœ¨æŒ‡å®šæ—¥æœŸèŒƒå›´å†…æ£€ç´¢åˆ°çš„æ–‡æ¡£ã€‚

è¿™å±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨ Timescale Vector é€šè¿‡æ£€ç´¢ä¸æŸ¥è¯¢ç›¸å…³çš„æ—¶é—´èŒƒå›´å†…çš„æ–‡æ¡£æ¥å¢å¼ºæ£€ç´¢å¢å¼ºç”Ÿæˆã€‚

## 3. ä½¿ç”¨ ANN æœç´¢ç´¢å¼•åŠ é€ŸæŸ¥è¯¢

é€šè¿‡åœ¨åµŒå…¥åˆ—ä¸Šåˆ›å»ºç´¢å¼•ï¼Œå¯ä»¥åŠ é€Ÿç›¸ä¼¼æ€§æŸ¥è¯¢ã€‚åªæœ‰åœ¨æ‘„å–äº†å¤§é‡æ•°æ®åï¼Œæ‰åº”æ‰§è¡Œæ­¤æ“ä½œã€‚

Timescale Vector æ”¯æŒä»¥ä¸‹ç´¢å¼•ï¼š
- timescale_vector ç´¢å¼• (tsv)ï¼šä¸€ç§å— disk-ann å¯å‘çš„å›¾å½¢ç´¢å¼•ï¼Œç”¨äºå¿«é€Ÿç›¸ä¼¼æ€§æœç´¢ï¼ˆé»˜è®¤ï¼‰ã€‚
- pgvector çš„ HNSW ç´¢å¼•ï¼šä¸€ç§å±‚æ¬¡å¯å¯¼èˆªçš„å°ä¸–ç•Œå›¾ç´¢å¼•ï¼Œç”¨äºå¿«é€Ÿç›¸ä¼¼æ€§æœç´¢ã€‚
- pgvector çš„ IVFFLAT ç´¢å¼•ï¼šä¸€ç§å€’æ’æ–‡ä»¶ç´¢å¼•ï¼Œç”¨äºå¿«é€Ÿç›¸ä¼¼æ€§æœç´¢ã€‚

é‡è¦æç¤ºï¼šåœ¨ PostgreSQL ä¸­ï¼Œæ¯ä¸ªè¡¨åªèƒ½åœ¨ç‰¹å®šåˆ—ä¸Šæ‹¥æœ‰ä¸€ä¸ªç´¢å¼•ã€‚å› æ­¤ï¼Œå¦‚æœæ‚¨æƒ³æµ‹è¯•ä¸åŒç´¢å¼•ç±»å‹çš„æ€§èƒ½ï¼Œå¯ä»¥é€šè¿‡ä»¥ä¸‹æ–¹å¼è¿›è¡Œï¼š(1) åˆ›å»ºå¤šä¸ªå…·æœ‰ä¸åŒç´¢å¼•çš„è¡¨ï¼Œ(2) åœ¨åŒä¸€è¡¨ä¸­åˆ›å»ºå¤šä¸ªå‘é‡åˆ—å¹¶åœ¨æ¯åˆ—ä¸Šåˆ›å»ºä¸åŒçš„ç´¢å¼•ï¼Œæˆ–è€… (3) åˆ é™¤å¹¶é‡æ–°åˆ›å»ºåŒä¸€åˆ—ä¸Šçš„ç´¢å¼•å¹¶æ¯”è¾ƒç»“æœã€‚

```python
# Initialize an existing TimescaleVector store
COLLECTION_NAME = "timescale_commits"
embeddings = OpenAIEmbeddings()
db = TimescaleVector(
    collection_name=COLLECTION_NAME,
    service_url=SERVICE_URL,
    embedding_function=embeddings,
)
```

ä½¿ç”¨ `create_index()` å‡½æ•°è€Œä¸å¸¦é¢å¤–å‚æ•°å°†é»˜è®¤åˆ›å»ºä¸€ä¸ª timescale_vector_indexï¼Œä½¿ç”¨é»˜è®¤å‚æ•°ã€‚

```python
# create an index
# by default this will create a Timescale Vector (DiskANN) index
db.create_index()
```

æ‚¨è¿˜å¯ä»¥æŒ‡å®šç´¢å¼•çš„å‚æ•°ã€‚æœ‰å…³ä¸åŒå‚æ•°åŠå…¶å¯¹æ€§èƒ½å½±å“çš„å®Œæ•´è®¨è®ºï¼Œè¯·å‚é˜… Timescale Vector æ–‡æ¡£ã€‚

æ³¨æ„ï¼šæ‚¨ä¸éœ€è¦æŒ‡å®šå‚æ•°ï¼Œå› ä¸ºæˆ‘ä»¬è®¾ç½®äº†æ™ºèƒ½é»˜è®¤å€¼ã€‚ä½†å¦‚æœæ‚¨å¸Œæœ›é’ˆå¯¹ç‰¹å®šæ•°æ®é›†è¿›è¡Œå®éªŒä»¥è·å¾—æ›´å¥½çš„æ€§èƒ½ï¼Œæ‚¨å§‹ç»ˆå¯ä»¥æŒ‡å®šè‡ªå·±çš„å‚æ•°ã€‚

```python
# drop the old index
db.drop_index()

# create an index
# Note: You don't need to specify m and ef_construction parameters as we set smart defaults.
db.create_index(index_type="tsv", max_alpha=1.0, num_neighbors=50)
```

Timescale Vector è¿˜æ”¯æŒ HNSW ANN ç´¢å¼•ç®—æ³•ï¼Œä»¥åŠ ivfflat ANN ç´¢å¼•ç®—æ³•ã€‚åªéœ€åœ¨ `index_type` å‚æ•°ä¸­æŒ‡å®šè¦åˆ›å»ºçš„ç´¢å¼•ï¼Œå¹¶å¯é€‰åœ°æŒ‡å®šç´¢å¼•çš„å‚æ•°ã€‚

```python
# drop the old index
db.drop_index()

# Create an HNSW index
# Note: You don't need to specify m and ef_construction parameters as we set smart defaults.
db.create_index(index_type="hnsw", m=16, ef_construction=64)
```

```python
# drop the old index
db.drop_index()

# Create an IVFFLAT index
# Note: You don't need to specify num_lists and num_records parameters as we set smart defaults.
db.create_index(index_type="ivfflat", num_lists=20, num_records=1000)
```

ä¸€èˆ¬æ¥è¯´ï¼Œæˆ‘ä»¬å»ºè®®ä½¿ç”¨é»˜è®¤çš„ timescale vector ç´¢å¼•æˆ– HNSW ç´¢å¼•ã€‚

```python
# drop the old index
db.drop_index()
# Create a new timescale vector index
db.create_index()
```

## 4. è‡ªæŸ¥è¯¢æ£€ç´¢å™¨ä¸ Timescale Vector

Timescale Vector è¿˜æ”¯æŒè‡ªæŸ¥è¯¢æ£€ç´¢å™¨åŠŸèƒ½ï¼Œä½¿å…¶èƒ½å¤Ÿè¿›è¡Œè‡ªæˆ‘æŸ¥è¯¢ã€‚ç»™å®šä¸€ä¸ªåŒ…å«æŸ¥è¯¢è¯­å¥å’Œè¿‡æ»¤å™¨ï¼ˆå•ä¸ªæˆ–å¤åˆï¼‰çš„è‡ªç„¶è¯­è¨€æŸ¥è¯¢ï¼Œæ£€ç´¢å™¨ä½¿ç”¨æŸ¥è¯¢æ„é€  LLM é“¾æ¥ç¼–å†™ SQL æŸ¥è¯¢ï¼Œç„¶åå°†å…¶åº”ç”¨äº Timescale Vector å‘é‡å­˜å‚¨ä¸­çš„åº•å±‚ PostgreSQL æ•°æ®åº“ã€‚

æœ‰å…³è‡ªæŸ¥è¯¢çš„æ›´å¤šä¿¡æ¯ï¼Œè¯· [æŸ¥çœ‹æ–‡æ¡£](/docs/how_to/self_query)ã€‚

ä¸ºäº†è¯´æ˜ Timescale Vector çš„è‡ªæŸ¥è¯¢ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ç¬¬ 3 éƒ¨åˆ†ä¸­çš„ç›¸åŒ gitlog æ•°æ®é›†ã€‚

```python
COLLECTION_NAME = "timescale_commits"
vectorstore = TimescaleVector(
    embedding_function=OpenAIEmbeddings(),
    collection_name=COLLECTION_NAME,
    service_url=SERVICE_URL,
)
```

æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°†åˆ›å»ºè‡ªæŸ¥è¯¢æ£€ç´¢å™¨ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬éœ€è¦æå‰æä¾›ä¸€äº›å…³äºæ–‡æ¡£æ”¯æŒçš„å…ƒæ•°æ®å­—æ®µçš„ä¿¡æ¯ä»¥åŠæ–‡æ¡£å†…å®¹çš„ç®€çŸ­æè¿°ã€‚

```python
from langchain.chains.query_constructor.base import AttributeInfo
from langchain.retrievers.self_query.base import SelfQueryRetriever
from langchain_openai import OpenAI

# å‘ LLM æä¾›æœ‰å…³å…ƒæ•°æ®å­—æ®µçš„ä¿¡æ¯
metadata_field_info = [
    AttributeInfo(
        name="id",
        description="ä»æäº¤æ—¥æœŸç”Ÿæˆçš„ UUID v1",
        type="uuid",
    ),
    AttributeInfo(
        name="date",
        description="ä»¥ timestamptz æ ¼å¼è¡¨ç¤ºçš„æäº¤æ—¥æœŸ",
        type="timestamptz",
    ),
    AttributeInfo(
        name="author_name",
        description="æäº¤ä½œè€…çš„å§“å",
        type="string",
    ),
    AttributeInfo(
        name="author_email",
        description="æäº¤ä½œè€…çš„ç”µå­é‚®ä»¶åœ°å€",
        type="string",
    ),
]
document_content_description = "åŒ…å«æäº¤å“ˆå¸Œã€ä½œè€…ã€æäº¤æ—¥æœŸã€å˜æ›´æ‘˜è¦å’Œå˜æ›´è¯¦æƒ…çš„ git æ—¥å¿—æäº¤æ‘˜è¦"

# ä» LLM å®ä¾‹åŒ–è‡ªæŸ¥è¯¢æ£€ç´¢å™¨
llm = OpenAI(temperature=0)
retriever = SelfQueryRetriever.from_llm(
    llm,
    vectorstore,
    document_content_description,
    metadata_field_info,
    enable_limit=True,
    verbose=True,
)
```

ç°åœ¨è®©æˆ‘ä»¬åœ¨ gitlog æ•°æ®é›†ä¸Šæµ‹è¯•è‡ªæŸ¥è¯¢æ£€ç´¢å™¨ã€‚

è¿è¡Œä»¥ä¸‹æŸ¥è¯¢ï¼Œå¹¶æ³¨æ„å¦‚ä½•åœ¨è‡ªç„¶è¯­è¨€ä¸­æŒ‡å®šæŸ¥è¯¢ã€å¸¦è¿‡æ»¤å™¨çš„æŸ¥è¯¢å’Œå¸¦å¤åˆè¿‡æ»¤å™¨ï¼ˆå¸¦æœ‰ ANDã€OR çš„è¿‡æ»¤å™¨ï¼‰ï¼Œè‡ªæŸ¥è¯¢æ£€ç´¢å™¨å°†æŠŠè¯¥æŸ¥è¯¢è½¬æ¢ä¸º SQLï¼Œå¹¶åœ¨ Timescale Vector PostgreSQL å‘é‡å­˜å‚¨ä¸Šæ‰§è¡Œæœç´¢ã€‚

è¿™å±•ç¤ºäº†è‡ªæŸ¥è¯¢æ£€ç´¢å™¨çš„å¼ºå¤§åŠŸèƒ½ã€‚æ‚¨å¯ä»¥ä½¿ç”¨å®ƒå¯¹å‘é‡å­˜å‚¨æ‰§è¡Œå¤æ‚æœç´¢ï¼Œè€Œæ— éœ€æ‚¨æˆ–æ‚¨çš„ç”¨æˆ·ç›´æ¥ç¼–å†™ä»»ä½• SQLï¼

```python
# æ­¤ç¤ºä¾‹æŒ‡å®šäº†ä¸€ä¸ªç›¸å…³æŸ¥è¯¢
retriever.invoke("å¯¹è¿ç»­èšåˆåšäº†å“ªäº›æ”¹è¿›ï¼Ÿ")
```
```output
/Users/avtharsewrathan/sideprojects2023/timescaleai/tsv-langchain/langchain/libs/langchain/langchain/chains/llm.py:275: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.
  warnings.warn(
``````output
query='improvements to continuous aggregates' filter=None limit=None
```






```python
# æ­¤ç¤ºä¾‹æŒ‡å®šäº†ä¸€ä¸ªè¿‡æ»¤å™¨
retriever.invoke("Sven Klemm æ·»åŠ äº†å“ªäº›æäº¤ï¼Ÿ")
```
```output
query=' ' filter=Comparison(comparator=<Comparator.EQ: 'eq'>, attribute='author_name', value='Sven Klemm') limit=None
```


```python
# æ­¤ç¤ºä¾‹æŒ‡å®šäº†ä¸€ä¸ªæŸ¥è¯¢å’Œè¿‡æ»¤å™¨
retriever.invoke("Sven Klemm æ·»åŠ äº†å“ªäº›å…³äº timescaledb_functions çš„æäº¤ï¼Ÿ")
```
```output
query='timescaledb_functions' filter=Comparison(comparator=<Comparator.EQ: 'eq'>, attribute='author_name', value='Sven Klemm') limit=None
```



```python
# æ­¤ç¤ºä¾‹æŒ‡å®šäº†ä¸€ä¸ªåŸºäºæ—¶é—´çš„è¿‡æ»¤å™¨
retriever.invoke("åœ¨ 2023 å¹´ 7 æœˆæ·»åŠ äº†å“ªäº›æäº¤ï¼Ÿ")
```
```output
query=' ' filter=Operation(operator=<Operator.AND: 'and'>, arguments=[Comparison(comparator=<Comparator.GTE: 'gte'>, attribute='date', value='2023-07-01T00:00:00Z'), Comparison(comparator=<Comparator.LTE: 'lte'>, attribute='date', value='2023-07-31T23:59:59Z')]) limit=None
```




```python
# æ­¤ç¤ºä¾‹æŒ‡å®šäº†ä¸€ä¸ªæŸ¥è¯¢å’Œ LIMIT å€¼
retriever.invoke("å…³äºåˆ†å±‚è¿ç»­èšåˆçš„ä¸¤ä¸ªæäº¤æ˜¯ä»€ä¹ˆï¼Ÿ")
```
```output
query='hierarchical continuous aggregates' filter=None limit=2
```

## 5. ä½¿ç”¨ç°æœ‰çš„ TimescaleVector å‘é‡å­˜å‚¨

åœ¨ä¸Šè¿°ç¤ºä¾‹ä¸­ï¼Œæˆ‘ä»¬ä»ä¸€ç»„æ–‡æ¡£åˆ›å»ºäº†ä¸€ä¸ªå‘é‡å­˜å‚¨ã€‚ç„¶è€Œï¼Œæˆ‘ä»¬é€šå¸¸å¸Œæœ›å‘ç°æœ‰çš„å‘é‡å­˜å‚¨ä¸­æ’å…¥æ•°æ®å¹¶æŸ¥è¯¢æ•°æ®ã€‚è®©æˆ‘ä»¬çœ‹çœ‹å¦‚ä½•åˆå§‹åŒ–ã€å‘ç°æœ‰æ–‡æ¡£é›†åˆä¸­æ·»åŠ æ–‡æ¡£ä»¥åŠæŸ¥è¯¢ TimescaleVector å‘é‡å­˜å‚¨ä¸­çš„ç°æœ‰æ–‡æ¡£é›†åˆã€‚

è¦ä½¿ç”¨ç°æœ‰çš„ Timescale Vector å­˜å‚¨ï¼Œæˆ‘ä»¬éœ€è¦çŸ¥é“è¦æŸ¥è¯¢çš„è¡¨çš„åç§° (`COLLECTION_NAME`) å’Œäº‘ PostgreSQL æ•°æ®åº“çš„ URL (`SERVICE_URL`)ã€‚

```python
# Initialize the existing
COLLECTION_NAME = "timescale_commits"
embeddings = OpenAIEmbeddings()
vectorstore = TimescaleVector(
    collection_name=COLLECTION_NAME,
    service_url=SERVICE_URL,
    embedding_function=embeddings,
)
```

è¦å°†æ–°æ•°æ®åŠ è½½åˆ°è¡¨ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨ `add_document()` å‡½æ•°ã€‚è¯¥å‡½æ•°æ¥å—æ–‡æ¡£åˆ—è¡¨å’Œå…ƒæ•°æ®åˆ—è¡¨ã€‚å…ƒæ•°æ®å¿…é¡»åŒ…å«æ¯ä¸ªæ–‡æ¡£çš„å”¯ä¸€ idã€‚

å¦‚æœæ‚¨å¸Œæœ›æ–‡æ¡£ä¸å½“å‰æ—¥æœŸå’Œæ—¶é—´ç›¸å…³è”ï¼Œåˆ™æ— éœ€åˆ›å»º id åˆ—è¡¨ã€‚æ¯ä¸ªæ–‡æ¡£å°†è‡ªåŠ¨ç”Ÿæˆä¸€ä¸ª uuidã€‚

å¦‚æœæ‚¨å¸Œæœ›æ–‡æ¡£ä¸è¿‡å»çš„æ—¥æœŸå’Œæ—¶é—´ç›¸å…³è”ï¼Œå¯ä»¥ä½¿ç”¨ `timecale-vector` Python åº“ä¸­çš„ `uuid_from_time` å‡½æ•°åˆ›å»º id åˆ—è¡¨ï¼Œå¦‚ä¸Šé¢ç¬¬ 2 èŠ‚æ‰€ç¤ºã€‚è¯¥å‡½æ•°æ¥å—ä¸€ä¸ª datetime å¯¹è±¡ï¼Œå¹¶è¿”å›ä¸€ä¸ªå¸¦æœ‰æ—¥æœŸå’Œæ—¶é—´ç¼–ç çš„ uuidã€‚

```python
# Add documents to a collection in TimescaleVector
ids = vectorstore.add_documents([Document(page_content="foo")])
ids
```

```output
['a34f2b8a-53d7-11ee-8cc3-de1e4b2a0118']
```

```python
# Query the vectorstore for similar documents
docs_with_score = vectorstore.similarity_search_with_score("foo")
```

```python
docs_with_score[0]
```

```output
(Document(page_content='foo', metadata={}), 5.006789860928507e-06)
```

```python
docs_with_score[1]
```

```output
(Document(page_content='{"commit": " 00b566dfe478c11134bcf1e7bcf38943e7fafe8f", "author": "Fabr\\u00edzio de Royes Mello<fabriziomello@gmail.com>", "date": "Mon Mar 6 15:51:03 2023 -0300", "change summary": "Remove unused functions", "change details": "We don\'t use `ts_catalog_delete[_only]` functions anywhere and instead we rely on `ts_catalog_delete_tid[_only]` functions so removing it from our code base. "}', metadata={'id': 'd7f5c580-bc4f-11ed-9712-ffa0126a201a', 'date': '2023-03-6 15:51:03+-500', 'source': '/Users/avtharsewrathan/sideprojects2023/timescaleai/tsv-langchain/langchain/docs/docs/modules/ts_git_log.json', 'seq_num': 285, 'author_name': 'FabrÃ­zio de Royes Mello', 'commit_hash': ' 00b566dfe478c11134bcf1e7bcf38943e7fafe8f', 'author_email': 'fabriziomello@gmail.com'}),
 0.23607668446580354)
```

### åˆ é™¤æ•°æ®

æ‚¨å¯ä»¥é€šè¿‡ uuid æˆ–è€…é€šè¿‡å…ƒæ•°æ®çš„è¿‡æ»¤å™¨æ¥åˆ é™¤æ•°æ®ã€‚

```python
ids = vectorstore.add_documents([Document(page_content="Bar")])

vectorstore.delete(ids)
```

```output
True
```

é€šè¿‡å…ƒæ•°æ®åˆ é™¤å°¤å…¶æœ‰ç”¨ï¼Œå¦‚æœæ‚¨æƒ³å®šæœŸæ›´æ–°ä»ç‰¹å®šæ¥æºã€ç‰¹å®šæ—¥æœŸæˆ–å…¶ä»–å…ƒæ•°æ®å±æ€§æŠ“å–çš„ä¿¡æ¯ã€‚

```python
vectorstore.add_documents(
    [Document(page_content="Hello World", metadata={"source": "www.example.com/hello"})]
)
vectorstore.add_documents(
    [Document(page_content="Adios", metadata={"source": "www.example.com/adios"})]
)

vectorstore.delete_by_metadata({"source": "www.example.com/adios"})

vectorstore.add_documents(
    [
        Document(
            page_content="Adios, but newer!",
            metadata={"source": "www.example.com/adios"},
        )
    ]
)
```

```output
['c6367004-53d7-11ee-8cc3-de1e4b2a0118']
```

### è¦†ç›–å‘é‡å­˜å‚¨

å¦‚æœæ‚¨æœ‰ä¸€ä¸ªç°æœ‰çš„é›†åˆï¼Œå¯ä»¥é€šè¿‡æ‰§è¡Œ `from_documents` å¹¶å°† `pre_delete_collection` è®¾ç½®ä¸º True æ¥è¦†ç›–å®ƒã€‚

```python
db = TimescaleVector.from_documents(
    documents=docs,
    embedding=embeddings,
    collection_name=COLLECTION_NAME,
    service_url=SERVICE_URL,
    pre_delete_collection=True,
)
```

```python
docs_with_score = db.similarity_search_with_score("foo")
```

```python
docs_with_score[0]
```

## ç›¸å…³

- å‘é‡å­˜å‚¨ [æ¦‚å¿µæŒ‡å—](/docs/concepts/#vector-stores)
- å‘é‡å­˜å‚¨ [æ“ä½œæŒ‡å—](/docs/how_to/#vector-stores)